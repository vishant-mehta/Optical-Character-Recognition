{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my OCR  notebook",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut5mwGoDFAO8",
        "colab_type": "text"
      },
      "source": [
        "#**CRNN Model for handwritten-text-recognition**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE6HmGeo7Nai",
        "colab_type": "text"
      },
      "source": [
        "Mount your drive and go to the path where all the python files are stored ( For colab workers only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9fBiGfG6_5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wndG2tzc7IE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd\"drive/My Drive/OCR/src\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Njy6bLn7Z4y",
        "colab_type": "text"
      },
      "source": [
        "Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPuXIUg7aNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import html\n",
        "import string\n",
        "import numpy as np\n",
        "import numba as nb\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import datetime\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import CSVLogger, TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from dataloader import Load_dataset\n",
        "from preprocessing import preprocess_partitions\n",
        "from augmentation import data_augmentation\n",
        "from model import Flor_Model\n",
        "from evaluation import Evaluate\n",
        "\n",
        "from calc_loss import Loss_Calculation\n",
        "from generator import DataGenerator, Tokenizer\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kVpRWW07gZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install autocorrect\n",
        "\n",
        "from autocorrect import Speller"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpJG53r67jCc",
        "colab_type": "text"
      },
      "source": [
        "Defining variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udz4yXuQ7g4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = {'train':0, 'test':0, 'valid':0}\n",
        "steps = {'train':0, 'test':0, 'valid':0}\n",
        "source_path = os.path.join(\"..\", \"data\") #dataset path\n",
        "output_path = os.path.join(\"..\", \"output\") #store results here\n",
        "target_path = os.path.join(output_path, \"checkpoint_weights2.hdf5\") #path to save model weights\n",
        "input_size = (900, 128, 1)\n",
        "batch_size = 30\n",
        "\n",
        "print(source_path)\n",
        "print(target_path)\n",
        "print(output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N8Ik8y77sEL",
        "colab_type": "text"
      },
      "source": [
        "#Step 1: Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKt9ku5y7nxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = Load_dataset()\n",
        "dataset = ds.load_dataset(source_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGZzS8rF73Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = {'train':{'dt':[], 'gt':[]}, 'test':{'dt':dataset['test']['dt'], 'gt':dataset['test']['gt']}, 'valid': {'dt':[], 'gt':[]}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axekyFs-7wYZ",
        "colab_type": "text"
      },
      "source": [
        "#Step 2: Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUxP9Nn27zSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset =preprocess_partitions(input_size, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwAqnJLh75uk",
        "colab_type": "text"
      },
      "source": [
        "#Step 3: Augmenting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCCIiSkU770W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = data_augmentation(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmVgJKF47-D_",
        "colab_type": "text"
      },
      "source": [
        "#Step 4: Model creation & training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz61Ar9r8Hrq",
        "colab_type": "text"
      },
      "source": [
        "Create object of tokenizer class to get vocab size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TUYBzRp7_wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer(string.printable[:95])\n",
        "vocab_size = int(t.vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r23DuAio8Ktk",
        "colab_type": "text"
      },
      "source": [
        "Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04VBLT0-8LKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md = Flor_Model()\n",
        "model = md.create_newm(vocab_size+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8S5Y-Zx8Q9Z",
        "colab_type": "text"
      },
      "source": [
        "Compile and print model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KEja3yM8Sfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(learning_rate=0.001)\n",
        "cl = Loss_Calculation()\n",
        "model.compile(optimizer=optimizer, loss=cl.ctc_loss_lambda_func)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Vv-2KO8WXo",
        "colab_type": "text"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-46WkZOk8Wxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    CSVLogger(\n",
        "        filename=os.path.join(output_path, \"epochs.log\"), separator=\";\", append=True),\n",
        "    TensorBoard(\n",
        "        log_dir=output_path, histogram_freq=10, profile_batch=0, write_graph=True, write_images=False, update_freq=\"epoch\"),\n",
        "    ModelCheckpoint(\n",
        "        filepath=target_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True, verbose=1),\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\", min_delta=1e-8, patience=15, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", min_delta=1e-8, factor=0.2,patience=15, verbose=1)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNnCCSMq8jA8",
        "colab_type": "text"
      },
      "source": [
        "Tensorboard for Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h66NCDYx8jXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --reload_interval=300 --logdir={output_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9lLUzJU8qvG",
        "colab_type": "text"
      },
      "source": [
        "Loading the weights if the model is trained\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJqsk-s8rK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.isfile(target_path):\n",
        "    model.load_weights(target_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNe7DtP8wwt",
        "colab_type": "text"
      },
      "source": [
        "Decoding labels before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNXE5B_k8v7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for pt in ['train', 'test', 'valid']:\n",
        "    # decode sentences from byte\n",
        "    dataset[pt]['gt'] = [x.decode() for x in dataset[pt]['gt']]\n",
        "\n",
        "    # set size and setps\n",
        "    size[pt] = len(dataset[pt]['dt'])\n",
        "    steps[pt] = int(np.ceil(size[pt] / batch_size)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFQmGpb58zxz",
        "colab_type": "text"
      },
      "source": [
        "Creating object of DataGenerator to generate batches for training, test and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kji10we7837A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtgen = DataGenerator(dataset, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3545puR86PM",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcq-1hNL878a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = datetime.datetime.now()\n",
        "h = model.fit(\n",
        "    \n",
        "                x=dtgen.next_train_batch(), y=None, batch_size=30, epochs=150, verbose=1,\n",
        "                callbacks=callbacks, validation_split=0.0,\n",
        "                validation_data=dtgen.next_valid_batch(), shuffle=True,\n",
        "                class_weight=None, sample_weight=None,\n",
        "                initial_epoch=0, steps_per_epoch=steps['train'],\n",
        "                validation_steps=steps['valid'], validation_freq=1,\n",
        "                max_queue_size=10, workers=1,\n",
        "                use_multiprocessing=False\n",
        "            )\n",
        "total_time = datetime.datetime.now() - start_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDX4-4VA8-mW",
        "colab_type": "text"
      },
      "source": [
        "Details of the model after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwqYVebe9AjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = h.history['loss']\n",
        "val_loss = h.history['val_loss']\n",
        "\n",
        "min_val_loss = min(val_loss)\n",
        "min_val_loss_i = val_loss.index(min_val_loss)\n",
        "\n",
        "time_epoch = (total_time / len(loss))\n",
        "total_item = (size['train'] + size['valid'])\n",
        "\n",
        "t_corpus = \"\\n\".join([\n",
        "    f\"Total train images:      {dtgen.size['train']}\",\n",
        "    f\"Total validation images: {dtgen.size['valid']}\",\n",
        "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
        "    f\"Total time:              {total_time}\",\n",
        "    f\"Time per epoch:          {time_epoch}\",\n",
        "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
        "    f\"Total epochs:            {len(loss)}\",\n",
        "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
        "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
        "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
        "    lg.write(t_corpus)\n",
        "    print(t_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eflq8xHD9C2u",
        "colab_type": "text"
      },
      "source": [
        "#Step 5: Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIjAF2DW9Ghl",
        "colab_type": "text"
      },
      "source": [
        "Predict output for test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXGv9rRd9Fi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = datetime.datetime.now()\n",
        "\n",
        "predicts, _ = md.predict_model(model, x=dtgen.next_test_batch(), batch_size=None, verbose=1, steps=steps['test'], callbacks=None, max_queue_size=10,\n",
        "                  workers=1, use_multiprocessing=False, ctc_decode=True)\n",
        "\n",
        "# decode to string\n",
        "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "# mount predict corpus file\n",
        "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
        "    for pd, gt in zip(predicts, dtgen.dataset['test']['gt']):\n",
        "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bZs4oDL9KVl",
        "colab_type": "text"
      },
      "source": [
        "Applying autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP-8Gn719MTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spell = Speller(\"en\")\n",
        "\n",
        "autocorrect_predicts = []\n",
        "for j in range(len(predicts)):\n",
        "    y = []\n",
        "    words = predicts[j].split(\" \")\n",
        "    for word in words:\n",
        "        a = spell(word)\n",
        "        y.append(a)\n",
        "    y = \" \".join(y)\n",
        "    autocorrect_predicts.append(y)\n",
        "\n",
        "# mount predict corpus file\n",
        "with open(os.path.join(output_path, \"autocorrect_predict.txt\"), \"w\") as lg:\n",
        "    for pd, gt in zip(autocorrect_predicts, dtgen.dataset['test']['gt']):\n",
        "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjEka16u9Ooo",
        "colab_type": "text"
      },
      "source": [
        "Printing some of predicted outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8BJ2Tk99RxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,10):\n",
        "  img = dataset['test']['dt'][i]\n",
        "  lbl = dataset['test']['gt'][i]\n",
        "  cv2_imshow(cv2.transpose(img))\n",
        "  print(lbl)\n",
        "  print(predicts[i])\n",
        "  print(autocorrect_predicts[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsRQH9ZA9oB4",
        "colab_type": "text"
      },
      "source": [
        "#Step 6: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXidwK7G9oqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ev = Evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAZ1avj59ugE",
        "colab_type": "text"
      },
      "source": [
        "Evaluation before applying autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USjuQhUz9vaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate = ev.ocr_metrics(predicts=predicts,ground_truth=dataset['test']['gt'])\n",
        "e_corpus = \"\\n\".join([\n",
        "    f\"Total test images:    {size['test']}\",\n",
        "    f\"Total time:           {total_time}\",\n",
        "    f\"Time per item:        {total_time / size['test']}\\n\",\n",
        "    f\"Metrics:\",\n",
        "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
        "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
        "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
        "])\n",
        "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
        "    lg.write(e_corpus)\n",
        "    print(e_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UscIqZ0m93hQ",
        "colab_type": "text"
      },
      "source": [
        "Evaluation after applying autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geGL8R_L94Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autocorrect_evaluate = ev.ocr_metrics(predicts=autocorrect_predicts,ground_truth=dataset['test']['gt'])\n",
        "autocorrect_e_corpus = \"\\n\".join([\n",
        "    f\"Total test images:    {size['test']}\",\n",
        "    f\"Total time:           {total_time}\",\n",
        "    f\"Time per item:        {total_time / size['test']}\\n\",\n",
        "    f\"Metrics:\",\n",
        "    f\"Character Error Rate: {autocorrect_evaluate[0]:.8f}\",\n",
        "    f\"Word Error Rate:      {autocorrect_evaluate[1]:.8f}\",\n",
        "    f\"Sequence Error Rate:  {autocorrect_evaluate[2]:.8f}\"\n",
        "])\n",
        "with open(os.path.join(output_path, \"evaluate1.txt\"), \"w\") as lg:\n",
        "    lg.write(autocorrect_e_corpus)\n",
        "    print(autocorrect_e_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyLvR25d-aV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}